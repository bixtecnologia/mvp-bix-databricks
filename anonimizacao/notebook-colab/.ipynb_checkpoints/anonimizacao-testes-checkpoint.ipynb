{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a78eda7",
   "metadata": {},
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb94458",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2     \n",
    "import matplotlib.pyplot as plt    \n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from keras.preprocessing import image  \n",
    "import numpy as np  \n",
    "from keras.utils import np_utils\n",
    "from skimage.transform import resize   \n",
    "from google.colab.patches import cv2_imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0aa903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90da2011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# caso rode no colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abfa056",
   "metadata": {},
   "source": [
    "# YOLOv5\n",
    "\n",
    "Detecção de carros e pessoas com as bounding boxes preenchidas com blur. \n",
    "\n",
    "-- source: path para o video/foto a ser anonimizado\n",
    "\n",
    "-- project: path para a pasta de destino onde será armazenado o arquivo anonimizado\n",
    "\n",
    "-----------------\n",
    "O repositório utilizado tem diferenças em relação ao repositório original:\n",
    "- utils/plot.py: função box_label ao invés de escrever um retângulo com as coordenadas das bounding boxes, utiliza tais coordenadas para escrever um retangulo preenchido com blur. Linhas 103 -> 107\n",
    "- detect.py: a variável txt_path (linha 145) deve receber o input manual da pasta onde serão armazenados os dados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa314b2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!python yolov5/detect.py --img 640 --conf 0.3 --save-txt --source '/content/drive/MyDrive/Chapter Data Science/Comercial/POCs/POC qualidade do asfalto/data/videos raw/buracos_e_qualidade_asfalto.mp4' --classes 0 2 3 5 7 --project '/content/drive/MyDrive/teste databricks/cv/output/anonimo/exp-ycv4-blur' --hide-labels --hide-conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6f88b1",
   "metadata": {},
   "source": [
    "# OpenCV\n",
    "\n",
    "Utilizar a técnica de identificar os objetos em movimento e retirar o fundo da imagem. \n",
    "\n",
    "Sem muito sucesso. O background subtractor é uma técnica que funciona bem quando a câmera está estática e/ou sem movimento relativo em relação aos objetos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74299198",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_detector = cv2.createBackgroundSubtractorMOG2(history=100, varThreshold=150)\n",
    "\n",
    "def BacgroundSubtractor(frame):\n",
    "    bounding_boxes = []\n",
    "    # Threshold to draw the rectangle (bounding box)\n",
    "    area_threshold = (frame.shape[0]*frame.shape[1])*0.005 #0.5% of the image\n",
    "\n",
    "    # Create mask (Detects objects that are in motion)\n",
    "    mask = object_detector.apply(frame)\n",
    "    _, mask = cv2.threshold(mask, 254, 255, cv2.THRESH_BINARY) #Remove shadow\n",
    "\n",
    "    # Get contours based on mask\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "\n",
    "        # Get bounding box\n",
    "        if (area > area_threshold):\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            bounding_boxes.append((x, y, w, h))\n",
    "\n",
    "    classes = None\n",
    "    confidences = None\n",
    "\n",
    "    return bounding_boxes, classes, confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d2c263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(videopath4)\n",
    "out = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "output = cv2.VideoWriter('output.avi', fourcc, 20.0, (640,480), isColor=False)\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret==True:\n",
    "        frame = cv2.flip(frame,180)\n",
    "        \n",
    "        height, width, _ = frame.shape\n",
    "        \n",
    "        \n",
    "        # height, width\n",
    "        roi = frame[300:600, 500:800]    \n",
    "        cv2.imshow('roi', roi)\n",
    "        mask = out.apply(roi)\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        # print(contours)\n",
    "        \n",
    "        for cnt in contours:\n",
    "            \n",
    "            area = cv2.contourArea(cnt)\n",
    "            if area > 600:\n",
    "                \n",
    "            \n",
    "                cv2.drawContours(roi, [cnt], -1, (0, 255, 0), 2)\n",
    "        \n",
    "        output.write(outmask)\n",
    "\n",
    "        cv2.imshow('original', frame)\n",
    "        cv2.imshow('Motion Tracker', mask)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "\n",
    "output.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19a4edb",
   "metadata": {},
   "source": [
    "# YOLO + OpenCV\n",
    "\n",
    "A ideia é utilizar as previsões do Yolo para rastrear os carros nas imagens e delimitar com maior precisão as regiões para o OpenCV realizar a extração do fundo da imagem. \n",
    "\n",
    "Sem muito sucesso. Ao limitar a região de interesse, o background subtractor não é capaz de detectar corpos em movimento e diferenciar dos corpos estáticos/fundo da imagem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eebc63e",
   "metadata": {},
   "source": [
    "## YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f361e9ee",
   "metadata": {},
   "source": [
    "### Previsão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82150bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# previsão\n",
    "!python '/content/yolov5/detect.py' --img 640 --conf 0.3 --save-txt --source '/content/drive/MyDrive/Chapter Data Science/Comercial/POCs/POC qualidade do asfalto/data/videos raw/buracos_e_qualidade_asfalto.mp4' --classes 0 2 3 5 7 --project '/content/drive/MyDrive/teste databricks/cv/output/anonimo/exp-ycv4-blur' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e07576",
   "metadata": {},
   "source": [
    "### Manipulação dos dados da previsão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ea8598",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pasta com o caminho das labels previstas\n",
    "mypath = '/content/drive/MyDrive/teste databricks/cv/output/anonimo/exp-ycv4-blur/exp/labels/'\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "onlyfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfd8006",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = pd.DataFrame(onlyfiles)\n",
    "df_path['path'] = mypath\n",
    "entire_path = df_path['path'] + df_path[0]\n",
    "\n",
    "df_path.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ed74d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = df_path[0].str.split('_').apply(pd.Series)[4].str.split('.').apply(pd.Series)[0]\n",
    "df_txt = pd.DataFrame()\n",
    "for i in range(len(entire_path)):\n",
    "    df = pd.read_csv(entire_path[i],names=['class','1','2','3','4'] ,sep=\" \")\n",
    "    df['frame'] = numbers[i]\n",
    "    df_txt = pd.concat([df_txt , df ])\n",
    "\n",
    "df_txt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c388b126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertendo frames para segundos\n",
    "df_txt['frame'] = df_txt['frame'].astype(int)\n",
    "df_txt['segundos'] = df_txt['frame'] / 30\n",
    "df_txt['segundos'] = round(df_txt['segundos'],2)\n",
    "df_txt = df_txt.sort_values('segundos')\n",
    "df_txt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88516317",
   "metadata": {},
   "source": [
    "## OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf70165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df, img):\n",
    "  df_txt = pd.DataFrame()\n",
    "\n",
    "  for index, row in df.iterrows():\n",
    "\n",
    "    dh, dw, _ = img.shape\n",
    "    x = row['1']\n",
    "    y = row['2']\n",
    "    w = row['3']\n",
    "    h = row['4']\n",
    "    x_start = int((x - (w/2))*dw) \n",
    "    y_start = int((y - (h/2))*dh) \n",
    "    x_end = int((x + (w/2))*dw) \n",
    "    y_end = int((y + (h/2))*dh)\n",
    "\n",
    "    # caso as coordenadas estejam fora do limite do frame\n",
    "    if x_start < 0:\n",
    "        x_start = 0\n",
    "    if x_end > dw - 1:\n",
    "        x_end = dw - 1\n",
    "    if y_end < 0:\n",
    "        y_end = 0\n",
    "    if y_start > dh - 1:\n",
    "        y_start = dh - 1\n",
    "\n",
    "    df_txt = df_txt.append({'frame':row['frame'], 'index':row['class'], 'Xi': x_start,'Xf': x_end,'Yi': y_start, 'Yf':y_end}, ignore_index=True)\n",
    "    return df_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7715e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_capture = cv2.VideoCapture(videopath)\n",
    "\n",
    "vid_capture.get(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65ecb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_width = int(vid_capture.get(3))\n",
    "frame_height = int(vid_capture.get(4))\n",
    "frame_size = (frame_width, frame_height)\n",
    "\n",
    "output_video = cv2.VideoWriter('output.mp4', cv2.VideoWriter_fourcc('M','J','P','G'), 30, frame_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411edb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = cv2.createBackgroundSubtractorMOG2()\n",
    "vid_capture = cv2.VideoCapture(videopath6)\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "# output = cv2.VideoWriter('output.avi', fourcc, 20.0, (640,480), isColor=False)\n",
    "\n",
    "i=0\n",
    "while(vid_capture.isOpened()):\n",
    "    ret, frame = vid_capture.read()\n",
    "    print(i)\n",
    "    cv2.imshow('frame oficial', frame)\n",
    "    i += 1\n",
    "    if ret==True:\n",
    "        \n",
    "        height, width, _ = frame.shape\n",
    "        \n",
    "        cord_bb = df_bb.loc[df_bb['frame'] == i]\n",
    "        # print(cord_bb)\n",
    "\n",
    "        df_bbs = predict(pd.DataFrame(cord_bb), frame)\n",
    "        \n",
    "        for index, row in df_txt.iterrows():\n",
    "            Xi = int(row.Xi)\n",
    "            Xf = int(row.Xf)\n",
    "            Yi = int(row.Yi)\n",
    "            Yf = int(row.Yf)\n",
    "            # print(Xi)\n",
    "            # print(frame.shape)\n",
    "\n",
    "            roi = frame[Yi:Yf, Xi:Xf]\n",
    "            cv2.imshow('roi', roi)\n",
    "        \n",
    "            mask = out.apply(roi)\n",
    "            contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            for cnt in contours:\n",
    "\n",
    "                area = cv2.contourArea(cnt)\n",
    "                if area < 500:\n",
    "                    cv2.drawContours(roi, [cnt], -1, (0, 255, 0), 2)\n",
    "                    cv2.fillPoly(roi, pts =[cnt], color=(255,0,0))\n",
    "                    \n",
    "        cv2.imshow('output final',frame)\n",
    "        cv2.imshow('roi final', roi)\n",
    "        \n",
    "        cv2.waitKey(1)\n",
    "        \n",
    "    else:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
